{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import mediapipe as mp\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary with these\n",
    "body_parts={\n",
    "    0:\"nose\",\n",
    "    1:\"left_eye_inner\",\n",
    "    2:\"left_eye\",\n",
    "    3:\"left_eve_outer\",\n",
    "    4:\"right_eye_inner\",\n",
    "    5:\"right_eye\",\n",
    "    6:\"right_eye_outer\",\n",
    "    7:\"left_ear\",\n",
    "    8:\"right_ear\",\n",
    "    9:\"mouth_left\",\n",
    "    10:\"mouth_right\",\n",
    "    11:\"left_shoulder\",\n",
    "    12:\"right_shoulder\",\n",
    "    13:\"left_elbow\",\n",
    "    14:\"right_elbow\",\n",
    "    15:\"left_wrist\",\n",
    "    16:\"right_wrist\",\n",
    "    17:\"left_pinky\",\n",
    "    18:\"right_pinky\",\n",
    "    19:\"left index\",\n",
    "    20:\"right_index\",\n",
    "    21:\"left_thumb\",\n",
    "    22:\"right_thumb\",\n",
    "    23:\"left_hip\",\n",
    "    24:\"right_hip\",\n",
    "    25:\"left_knee\",\n",
    "    26:\"right_knee\",\n",
    "    27:\"left_ankle\",\n",
    "    28:\"right_ankle\",\n",
    "    29:\"left_heel\",\n",
    "    30:\"right_heel\",\n",
    "    31:\"left_foot_index\",\n",
    "    32:\"right_foot_index\"\n",
    "    }\n",
    "\n",
    "# ref_body_dict=[]\n",
    "# for i in body_parts:\n",
    "#     x=body_parts[i]\n",
    "#     y=i\n",
    "#     ref_body_dict.append((x,y))\n",
    "# ref_body_dict=dict(ref_body_dict)\n",
    "# ref_body_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimImg_points={'tree':{'right_knee':(55,426),'right_wrist':(162,88),'right_ankle':(158,409),\n",
    "                        'left_ankle':(166,589),'left_wrist':(184,88),'left_knee':(183,485),'nose':(181,172)},\n",
    "                'triangle':{'right_knee':(118,371),'right_wrist':(373,67),'right_ankle':(61,487),\n",
    "                        'left_ankle':(374,494),'left_wrist':(363,483),'left_knee':(293,412),'nose':(406,231)},\n",
    "                'wheel':{'right_knee':(144,134),'right_wrist':(455,268),'right_ankle':(90,267),\n",
    "                        'left_ankle':(90,267),'left_wrist':(455,268),'left_knee':(144,134),'nose':(416,160),'left_hip':(254,49)},\n",
    "                'downdog':{'right_knee':(110,153),'right_wrist':(416,261),'right_ankle':(62,250),\n",
    "                        'left_ankle':(62,250),'left_wrist':(416,261),'left_knee':(110,153),'nose':(312,203),'left_hip':(211,59)}\n",
    "              }\n",
    "\n",
    "refpoints={'triangle':'left_ankle','tree':'left_ankle','wheel':['left_hip','left_ankle'],'downdog':'right_ankle'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "293 504\n",
      "481 721\n"
     ]
    }
   ],
   "source": [
    "yog_pose=\"wheel\"\n",
    "dim_img=cv2.imread(f\"Images\\Dimension\\dim_{yog_pose}_org.png\")\n",
    "dim_h=dim_img.shape[0]\n",
    "dim_w=dim_img.shape[1]\n",
    "print(dim_h,dim_w)\n",
    "\n",
    "user_img=cv2.imread(rf'Images\\Input\\{yog_pose}.jpg')\n",
    "user_h,user_w=user_img.shape[:2]\n",
    "print(user_h,user_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def l_dist(a,b):\n",
    "    sq1=(a[0]-b[0])**2\n",
    "    sq2=(a[1]-b[1])**2\n",
    "    res=int(math.sqrt(sq1 + sq2))\n",
    "    return res\n",
    "\n",
    "def med_pipe(img):\n",
    "    mpPose = mp.solutions.pose\n",
    "    pose = mpPose.Pose()\n",
    "    mpDraw = mp.solutions.drawing_utils # For drawing keypoints\n",
    "    points = mpPose.PoseLandmark # Landmarks\n",
    "    # img = cv2.imread(r'images\\tree.jpg')\n",
    "    imageWidth, imageHeight = img.shape[:2]\n",
    "    imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    blank = np.zeros(img.shape) # Blank image\n",
    "    results = pose.process(imgRGB)\n",
    "    if results.pose_landmarks:\n",
    "        mpDraw.draw_landmarks(blank, results.pose_landmarks, mpPose.POSE_CONNECTIONS) # draw landmarks on blank\n",
    "        landmarks = results.pose_landmarks.landmark\n",
    "    return results\n",
    "\n",
    "def inference(img):\n",
    "    pose_pts=med_pipe(img)\n",
    "    comb_list=[]\n",
    "    body_points=[]\n",
    "    for id, lm in enumerate(pose_pts.pose_landmarks.landmark):\n",
    "        h, w,c = img.shape\n",
    "    # print(id, lm)\n",
    "        cx, cy = int(lm.x*w), int(lm.y*h)\n",
    "        comb_list.append((cx,cy))\n",
    "    comb_list=dict(enumerate(comb_list))\n",
    "    for i in comb_list:\n",
    "        x=body_parts[i]\n",
    "        y=comb_list[i]\n",
    "        body_points.append((x,y))\n",
    "    body_points=dict(body_points)\n",
    "    print(body_points.keys())\n",
    "    return body_points\n",
    "    \n",
    "def getimg_ratio(list_of_pairs,body_points,dimImg_points):\n",
    "    list_of_ratios=[]\n",
    "    for pair in list_of_pairs:\n",
    "        user_dist=l_dist(body_points[pair[0]],body_points[pair[1]])\n",
    "        dim_dist=l_dist(dimImg_points[yog_pose][pair[0]],dimImg_points[yog_pose][pair[1]])\n",
    "        ratio=user_dist/dim_dist\n",
    "        list_of_ratios.append(ratio)\n",
    "    avg_ratio=np.average(list_of_ratios)\n",
    "    print(avg_ratio)\n",
    "    return avg_ratio\n",
    "\n",
    "def scaling(dim_img,ratio,dimImg_points,yog_pose):\n",
    "    dim_image_scaled=cv2.resize(dim_img,(int(dim_w*ratio),int(dim_h*ratio)))\n",
    "    for body_part in dimImg_points[yog_pose].keys():\n",
    "        dimImg_points[yog_pose][body_part]=[int(dimImg_points[yog_pose][body_part][0]*ratio),int(dimImg_points[yog_pose][body_part][1]*ratio)]\n",
    "    print(dim_image_scaled.shape)\n",
    "    print(dimImg_points)\n",
    "    return dimImg_points,dim_image_scaled\n",
    "\n",
    "def add_padding(user_img,dim_img_scaled,yog_pose,dimImg_points_scaled,body_points):\n",
    "    leftdist=dimImg_points_scaled[yog_pose][refpoints[yog_pose]][0]\n",
    "    rightdist=dim_img_scaled.shape[1]-leftdist\n",
    "    topdist=dimImg_points_scaled[yog_pose][refpoints[yog_pose]][1]\n",
    "    bottomdist=dim_img_scaled.shape[0]-topdist\n",
    "    \n",
    "    user_leftdist=body_points[refpoints[yog_pose]][0]\n",
    "    user_rightdist=user_img.shape[1]-user_leftdist\n",
    "    user_topdist=body_points[refpoints[yog_pose]][1]\n",
    "    user_bottomdist=user_img.shape[0]-user_topdist\n",
    "\n",
    "    right =user_rightdist-rightdist\n",
    "    left = user_leftdist-leftdist\n",
    "    top = user_topdist-topdist\n",
    "    bottom =user_bottomdist-bottomdist\n",
    "    print(right,left,top,bottom)\n",
    "    result=cv2.copyMakeBorder(dim_img_scaled, top, bottom, left, right, cv2.BORDER_CONSTANT,(0,0,0))\n",
    "    print(result.shape)\n",
    "    return result\n",
    "\n",
    "def transparent_overlay(user_img,dimimg_padded):\n",
    "    background = user_img\n",
    "    overlay=dimimg_padded\n",
    "    alpha_channel = overlay[:, :, 2] / 255 # convert from 0-255 to 0.0-1.0\n",
    "    overlay_colors = overlay[:, :, :3]\n",
    "    alpha_mask = np.dstack((alpha_channel, alpha_channel, alpha_channel))\n",
    "    # The background image is larger than the overlay so we'll take a subsection of the background that matches the\n",
    "    # dimensions of the overlay.\n",
    "    # NOTE: For simplicity, the overlay is applied to the top-left corner of the background(0,0). An x and y offset\n",
    "    # could be used to place the overlay at any position on the background.\n",
    "    h, w = overlay.shape[:2]\n",
    "    background_subsection = background[0:h, 0:w]\n",
    "    # combine the background with the overlay image weighted by alpha\n",
    "    composite = background_subsection * (1 - alpha_mask) + overlay_colors * alpha_mask\n",
    "    # overwrite the section of the background image that has been updated\n",
    "    background[0:h, 0:w] = composite\n",
    "    cv2.imwrite(f'Images\\Overlay\\{yog_pose}_overlay.png', background)\n",
    "    cv2.imshow('combined.png', background)\n",
    "    cv2.waitKey()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_padding(user_img,dim_img_scaled,yog_pose,dimImg_points_scaled,body_points):\n",
    "    if yog_pose=='wheel':\n",
    "        leftdist=dimImg_points_scaled[yog_pose][refpoints[yog_pose][0]][0]\n",
    "        rightdist=dim_img_scaled.shape[1]-leftdist\n",
    "        topdist=dimImg_points_scaled[yog_pose][refpoints[yog_pose][1]][1]\n",
    "        bottomdist=dim_img_scaled.shape[0]-topdist\n",
    "        \n",
    "        user_leftdist=body_points[refpoints[yog_pose][0]][0]\n",
    "        user_rightdist=user_img.shape[1]-user_leftdist\n",
    "        user_topdist=body_points[refpoints[yog_pose][1]][1]\n",
    "        user_bottomdist=user_img.shape[0]-user_topdist\n",
    "    else:\n",
    "        leftdist=dimImg_points_scaled[yog_pose][refpoints[yog_pose]][0]\n",
    "        rightdist=dim_img_scaled.shape[1]-leftdist\n",
    "        topdist=dimImg_points_scaled[yog_pose][refpoints[yog_pose]][1]\n",
    "        bottomdist=dim_img_scaled.shape[0]-topdist\n",
    "        \n",
    "        user_leftdist=body_points[refpoints[yog_pose]][0]\n",
    "        user_rightdist=user_img.shape[1]-user_leftdist\n",
    "        user_topdist=body_points[refpoints[yog_pose]][1]\n",
    "        user_bottomdist=user_img.shape[0]-user_topdist\n",
    "\n",
    "    right =user_rightdist-rightdist\n",
    "    left = user_leftdist-leftdist\n",
    "    top = user_topdist-topdist\n",
    "    bottom =user_bottomdist-bottomdist\n",
    "    print(right,left,top,bottom)\n",
    "    result=cv2.copyMakeBorder(dim_img_scaled, top, bottom, left, right, cv2.BORDER_CONSTANT,(0,0,0))\n",
    "    print(result.shape)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['nose', 'left_eye_inner', 'left_eye', 'left_eve_outer', 'right_eye_inner', 'right_eye', 'right_eye_outer', 'left_ear', 'right_ear', 'mouth_left', 'mouth_right', 'left_shoulder', 'right_shoulder', 'left_elbow', 'right_elbow', 'left_wrist', 'right_wrist', 'left_pinky', 'right_pinky', 'left index', 'right_index', 'left_thumb', 'right_thumb', 'left_hip', 'right_hip', 'left_knee', 'right_knee', 'left_ankle', 'right_ankle', 'left_heel', 'right_heel', 'left_foot_index', 'right_foot_index'])\n"
     ]
    }
   ],
   "source": [
    "body_points=inference(user_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.174825174825175\n"
     ]
    }
   ],
   "source": [
    "ratio=getimg_ratio([['left_knee','left_ankle'],['right_ankle','right_knee']],body_points,dimImg_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(344, 592, 3)\n",
      "{'tree': {'right_knee': (55, 426), 'right_wrist': (162, 88), 'right_ankle': (158, 409), 'left_ankle': (166, 589), 'left_wrist': (184, 88), 'left_knee': (183, 485), 'nose': (181, 172)}, 'triangle': {'right_knee': (118, 371), 'right_wrist': (373, 67), 'right_ankle': (61, 487), 'left_ankle': (374, 494), 'left_wrist': (363, 483), 'left_knee': (293, 412), 'nose': (406, 231)}, 'wheel': {'right_knee': [169, 157], 'right_wrist': [534, 314], 'right_ankle': [105, 313], 'left_ankle': [105, 313], 'left_wrist': [534, 314], 'left_knee': [169, 157], 'nose': [488, 187], 'left_hip': [298, 57]}, 'downdog': {'right_knee': (110, 153), 'right_wrist': (416, 261), 'right_ankle': (62, 250), 'left_ankle': (62, 250), 'left_wrist': (416, 261), 'left_knee': (110, 153), 'nose': (312, 203), 'left_hip': (211, 59)}}\n"
     ]
    }
   ],
   "source": [
    "dimImg_points_scaled,dim_img_scaled=scaling(dim_img,ratio,dimImg_points,yog_pose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92 37 71 66\n",
      "(481, 721, 3)\n"
     ]
    }
   ],
   "source": [
    "dimimg_padded=add_padding(user_img,dim_img_scaled,yog_pose,dimImg_points_scaled,body_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(481, 721, 3)\n",
      "(481, 721, 3)\n"
     ]
    }
   ],
   "source": [
    "# cv2.imshow(\"user\",user_img)\n",
    "# cv2.imshow(\"dim\",dimimg_padded)\n",
    "print(user_img.shape)\n",
    "print(dimimg_padded.shape)\n",
    "# cv2.imwrite(f\"Images\\Dimension padded\\dim_{yog_pose}_padded.png\",dimimg_padded)\n",
    "# cv2.waitKey()\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dim_transparent=cv2.imread(f\"Images\\Dimension transparent\\dimimgpadded_{yog_pose}_transparent.png\",cv2.IMREAD_UNCHANGED)\n",
    "transparent_overlay(user_img,dimimg_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dimimg_padded = Image.open(f\"Images\\Dimension padded\\dim_{yog_pose}_padded.png\")\n",
    "# def convertImage(dimimg_padded):\n",
    "#     # img = Image.open(f\"Images_output\\dimimg_padded.png\")\n",
    "#     img = dimimg_padded.convert(\"RGBA\")\n",
    "  \n",
    "#     datas = img.getdata()\n",
    "  \n",
    "#     newData = []\n",
    "  \n",
    "#     for item in datas:\n",
    "#         if (item[0] == 255 and item[1] == 255 and item[2] == 255) or (item[0] == 0 and item[1] == 0 and item[2] == 0):\n",
    "#             newData.append((255, 255, 255, 0))\n",
    "#         else:\n",
    "#             newData.append(item)\n",
    "  \n",
    "#     img.putdata(newData)\n",
    "#     img.save(f\"Images\\Dimension transparent\\dimimgpadded_{yog_pose}_transparent.png\", \"PNG\")\n",
    "#     print(\"Successful\")\n",
    "#     # return img \n",
    "\n",
    "# convertImage(dimimg_padded)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "540c31e3c6e69c862d82fa5161a105014835cdc23564856d41aa187606f7a1c9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
